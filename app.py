# -*- coding: utf-8 -*-
"""Untitled93.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q56eqQ07gVkvWlIWCSAPt99YtWXIa3k9
"""

!pip install -r requirements.txt

!pip install streamlit pyngrok --quiet

import streamlit as st
import pandas as pd
import json
import os
import threading
import time
from pyngrok import ngrok
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.docstore.document import Document
from pydantic import BaseModel, validator

# Set OpenAI key manually if not using st.secrets
os.environ["OPENAI_API_KEY"] = "Your API Key"

# Set ngrok auth token
ngrok.set_auth_token("Your ngrok Auth token")

with open("app.py", "w") as f:
    f.write('''
import streamlit as st
import pandas as pd
import json
from pydantic import BaseModel, validator
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.docstore.document import Document

class TaxonomyRule(BaseModel):#Pydantic validator
    audience_segment: str
    campaign_type: str
    utm_source: str
    template_logic: str
    offer_type_logic: str

    @validator('audience_segment')
    def validate_audience(cls, v):
        assert v in ['retention', 'acquisition', 'loyalty']
        return v

    @validator('campaign_type')
    def validate_campaign(cls, v):
        assert v in ['promo', 'transactional', 'nurture']
        return v

    @validator('template_logic', 'offer_type_logic')
    def validate_logic(cls, v):
        assert v in ['filename_split', 'subject_keywords', 'ignore']
        return v

embedding_model = OpenAIEmbeddings()
plain_text_rules = [
    "For any source ID that starts with klaviyo_, set audience_segment to retention, campaign_type to promo, utm_source to klaviyo. Extract template_id from the filename, and offer_type from the subject line.",
    "For any source ID that starts with sfmc_, set audience_segment to acquisition, campaign_type to transactional, utm_source to sfmc. Extract template_id from the filename and ignore offer_type."
]#Rules in plain english
documents = [Document(page_content=rule) for rule in plain_text_rules]
vectorstore = FAISS.from_documents(documents, embedding_model)
retriever = vectorstore.as_retriever()#Vector store retriver for the Rules from Vector DB

prompt = PromptTemplate.from_template("""
You are a taxonomy engine. Convert the retrieved rule into a structured JSON object with the following structure:

{{
  "source_pattern": "<pattern string>",
  "rules": {{
    "audience_segment": "retention | acquisition | loyalty",
    "campaign_type": "promo | transactional | nurture",
    "utm_source": "<string>",
    "template_logic": "filename_split | ignore",
    "offer_type_logic": "subject_keywords | ignore"
  }}
}}

Respond ONLY in valid JSON.

Context:
{context}
""")

llm = ChatOpenAI(temperature=0)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True,output_key='result')#Defining Memory for the assistant
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt},
    memory=memory,
    return_source_documents=True,
    input_key="query",
    output_key="result"
)#Defining chain

st.title("AI-Powered Taxonomy Generator")
input_mode = st.radio("Choose input method:", ["Manual Entry", "CSV Upload"])
metadata_list = []

if input_mode == "Manual Entry":
    with st.form("manual_form"):
        source_id = st.text_input("Source ID")
        subject = st.text_input("Subject Line")
        filename = st.text_input("Filename")
        submitted = st.form_submit_button("Generate")
        if submitted:
            metadata_list.append({"source_id": source_id, "subject": subject, "filename": filename})

elif input_mode == "CSV Upload":
    uploaded_file = st.file_uploader("Upload CSV with columns: source_id, subject, filename", type="csv")
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        metadata_list = df.to_dict(orient="records")
# This is to handle different type of Uploads from the User
if metadata_list:
    results = []
    for metadata_input in metadata_list:
        query = {"query": f"How should I handle taxonomy for {metadata_input['source_id']} campaigns?"}
        try:
            response = qa_chain(query)
            rule_obj = json.loads(response['result'])
            validated = TaxonomyRule(**rule_obj["rules"])
            template_id = metadata_input["filename"].split("_")[-1].split(".")[0] if validated.template_logic == "filename_split" else None
            offer_type = metadata_input["subject"] if validated.offer_type_logic == "subject_keywords" else None
            final_output = {
                "source_id": metadata_input["source_id"],
                "audience_segment": validated.audience_segment,
                "campaign_type": validated.campaign_type,
                "utm_source": validated.utm_source,
                "template_id": template_id,
                "offer_type": offer_type
            }
            results.append(final_output)
        except Exception as e:
            st.error(f"Error processing {metadata_input['source_id']}: {e}")
    if results:
        final_df = pd.DataFrame(results)
        st.success("âœ… Taxonomy generation complete!")
        st.dataframe(final_df)
        csv = final_df.to_csv(index=False).encode("utf-8")#Writing output to CSV and then loading through Worflow to respective tables and also API uploads
        st.download_button("Download CSV", csv, "taxonomy_output.csv", "text/csv")
''')

# ----- Run Streamlit in background ----- #
def run():
    os.system("streamlit run app.py")

thread = threading.Thread(target=run)
thread.start()
time.sleep(5)

public_url = ngrok.connect(addr="8501")
print(f"ðŸ”— Streamlit app is live at: {public_url}")

st.write(f"ðŸ”— Your Streamlit app is live at: {public_url}")

ngrok.kill()